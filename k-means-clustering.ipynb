{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio\n",
    "sound_file = './sound/beep-01a.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (3,4,6,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('FACTDATA_MAR2017.txt')\n",
    "# fix datatypes\n",
    "column_names = df.columns.values\n",
    "column_datatypes = {}\n",
    "for i in range(16):\n",
    "    column_datatypes[column_names[i]] = str\n",
    "column_datatypes[column_names[16]] = np.int64\n",
    "for i in range(17, 19):\n",
    "    column_datatypes[column_names[i]] = np.float64\n",
    "#print len(column_datatypes)\n",
    "# Reload dataset\n",
    "df = pd.read_csv('FACTDATA_MAR2017.txt', dtype=column_datatypes)\n",
    "# Clean data\n",
    "df = df[(df.WORKSCH != '*') &\n",
    "        (df.SALLVL != 'Z') &\n",
    "        (df.PATCO != '9') &\n",
    "        (df.AGELVL != 'Z') & \n",
    "        (df.LOSLVL != 'Z') & \n",
    "        (df.SUPERVIS != '*') &\n",
    "        (df.GSEGRD != '**') &\n",
    "        (df.TOA != '**') &\n",
    "        (df.TOA != '99') &\n",
    "        (df.EDLVL != '**') & \n",
    "        (df.EDLVL.notnull())]\n",
    "# Prepare data\n",
    "# Age Level\n",
    "# Print age level dataframe\n",
    "age_level = pd.read_csv('DTagelvl.txt')\n",
    "age_lvls = [chr(num) for num in range(ord('A'), ord('A') + 11)]\n",
    "age_lvlt = 17\n",
    "age_dict = {}\n",
    "for age_lvl in age_lvls:\n",
    "    age_dict[age_lvl] = age_lvlt\n",
    "    age_lvlt += 5\n",
    "df['AGE'] = df['AGELVL'].map(lambda x: age_dict[x])\n",
    "# Educational Level\n",
    "# Print educational level dataframe\n",
    "edu_level = pd.read_csv('DTedlvl.txt')\n",
    "# Take the EDLVL and map to values in the EDLVLTYP column\n",
    "# Build dictionary of values\n",
    "edlvl_dict = {}\n",
    "edlvls_available = np.unique(df['EDLVL'])\n",
    "for edlvl in edlvls_available:\n",
    "    edlvl_dict[edlvl] = int(edu_level[edu_level.EDLVL == edlvl].iloc[0].EDLVLTYP)\n",
    "\n",
    "get_edlvl_type = lambda x: edlvl_dict[x]\n",
    "df['EDLVLTYP'] = df['EDLVL'].map(get_edlvl_type)\n",
    "# Supervisory Status\n",
    "# Print supervisory status dataframe\n",
    "supervis_status = pd.read_csv('DTsuper.txt')\n",
    "# Take the SUPERVIS and map to values in the SUPERTYP column\n",
    "# Build dictionary of values\n",
    "supervis_dict = {}\n",
    "supervis_available = np.unique(df['SUPERVIS'])\n",
    "for supervis in supervis_available:\n",
    "    # 3 for supervisor, 2 for leader and 1 for non-supervisor\n",
    "    supervis_dict[supervis] = 4 - int(supervis_status[supervis_status.SUPERVIS == supervis].iloc[0].SUPERTYP)\n",
    "\n",
    "get_supervis_type = lambda x: supervis_dict[x]\n",
    "df['SUPERTYP'] = df['SUPERVIS'].map(get_supervis_type)\n",
    "# Work schedule\n",
    "# Print work schedule dataframe\n",
    "work_schedule = pd.read_csv('DTwrksch.txt')\n",
    "# Take the WORKSCH and map to values in the WSTYP column\n",
    "# Build dictionary of values\n",
    "worksch_dict = {}\n",
    "worksch_available = np.unique(df['WORKSCH'])\n",
    "for worksch in worksch_available:\n",
    "    # 2 for full-time and 1 for part-time\n",
    "    worksch_dict[worksch] = 3 - int(work_schedule[work_schedule.WORKSCH == worksch].iloc[0].WSTYP)\n",
    "\n",
    "get_worksch_type = lambda x: worksch_dict[x]\n",
    "df['WSTYP'] = df['WORKSCH'].map(get_worksch_type)\n",
    "numeric_features = ['AGE', 'EDLVLTYP', 'SUPERTYP', 'WSTYP', 'SALARY', 'LOS']\n",
    "numeric_features_df = df[numeric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaled_data = scale(numeric_features_df)\n",
    "cluster = KMeans(init='k-means++', n_clusters=scaled_data.shape[1], n_init=10).fit(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of KMeans with k-means++ init\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Evaluation of KMeans with random init\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Evaluation of KMeans with pca init\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The shape of the initial centers ((6L, 6L)) does not match the number of clusters 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4c440a0a874a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mkm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0minertia\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda2\\lib\\site-packages\\sklearn\\cluster\\k_means_.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    887\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda2\\lib\\site-packages\\sklearn\\cluster\\k_means_.pyc\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__array__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0m_validate_center_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0minit\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mX_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda2\\lib\\site-packages\\sklearn\\cluster\\k_means_.pyc\u001b[0m in \u001b[0;36m_validate_center_shape\u001b[0;34m(X, n_centers, centers)\u001b[0m\n\u001b[1;32m    149\u001b[0m         raise ValueError('The shape of the initial centers (%s) '\n\u001b[1;32m    150\u001b[0m                          \u001b[1;34m'does not match the number of clusters %i'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                          % (centers.shape, n_centers))\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcenters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: The shape of the initial centers ((6L, 6L)) does not match the number of clusters 2"
     ]
    }
   ],
   "source": [
    "# Find out the best number of clusters\n",
    "#pca = PCA(n_components=scaled_data.shape[1]).fit(scaled_data)\n",
    "cases = [\n",
    "    (KMeans, 'k-means++', {}, 'k-means++'),\n",
    "    (KMeans, 'random', {}, 'random')\n",
    "    #(KMeans, pca.components_, {}, 'pca')\n",
    "]\n",
    "\n",
    "plots = []\n",
    "legends = []\n",
    "\n",
    "n_runs = 5\n",
    "n_clusters_range = range(2, scaled_data.shape[1])\n",
    "\n",
    "X = scaled_data\n",
    "for factory, init, params, init_name in cases:\n",
    "    print ('Evaluation of {} with {} init'.format(factory.__name__, init_name))\n",
    "    inertia = np.empty((len(n_clusters_range), n_runs))\n",
    "    \n",
    "    for run_id in range(n_runs):\n",
    "        for i, n_clusters in enumerate(n_clusters_range):\n",
    "            print n_clusters\n",
    "            km = factory(n_clusters = n_clusters, init=init, random_state = run_id, n_init=10).fit(X)\n",
    "            inertia[i, run_id] = km.inertia_\n",
    "    p = plt.errorbar(n_clusters_range, inertia.mean(axis=1), inertia.std(axis=1))\n",
    "    plots.append(p[0])\n",
    "    legends.append(\"{} with {} init\".format(factory.__name__, init_name))\n",
    "    \n",
    "plt.xlabel('n_clusters')\n",
    "plt.ylabel('inertia')\n",
    "plt.legend(plots, legends)\n",
    "plt.title('Mean inertia for various number of clusters across {} runs'.format(n_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** On second thoughts, the results aren't that useful because it will certainly be the case that the more clusters one gets, the less the inertia will be. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "km = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
